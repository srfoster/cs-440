id: "m2-airport-optimization"
type: "short-answer"
chapter: 1
question: |
  **Solve the airport placement problem using continuous optimization.**

  **Level 0** Discuss the difference between discrete optimization (8-Queens) and continuous optimization (airport placement). When is "state space as a graph" not the right model?  What the significance of "gradient descent" and how does it help us find optimal solutions in continuous spaces?

  **Level 1** Formally define the airport placement problem.  Demonstrate by hand, with 3 towns, how to compute the objective function for a given airport location.  Demonstrate how a random search algorithm might find the optimal location.

  **Level 2** Using a language of your choice, implement a solution using gradient descent (compute partial derivatives ∂f/∂x and ∂f/∂y analytically). Visualize the objective function as a heat map.

  **Level 3** Prove that the optimal solution is the weighted centroid: x* = Σ(w_i * x_i)/Σw_i. Analyze why this problem has a single global optimum (convex function). Discuss how this differs from the 8-Queens landscape. Generalize to other continuous optimization problems: when can we use calculus vs. metaheuristics?
answer: |
  **Level 0: Discrete vs. Continuous Optimization**

  **Discrete Optimization (8-Queens):**
  - State space: Finite set of distinct configurations (8^8 = 16.7M states)
  - Transitions: Discrete moves between states (move queen to different row)
  - Natural graph model: States as nodes, moves as edges
  - Search methods: Hill climbing, simulated annealing, genetic algorithms
  - No calculus applicable (no derivatives in discrete space)

  **Continuous Optimization (Airport Placement):**
  - State space: Infinite points in continuous space (ℝ² for 2D location)
  - Transitions: Infinitesimal changes in any direction
  - Graph model breaks down: Infinite states, infinite neighbors per state
  - Search methods: Gradient descent, Newton's method, random search
  - Calculus is key: Use derivatives to find optimal direction

  **When "state space as a graph" is wrong:**
  - Variables are real-valued (positions, weights, probabilities)
  - Infinite or uncountably many states
  - Smooth objective functions where derivatives exist
  - Examples: Robot motion planning (continuous angles), parameter tuning (learning rates), resource allocation (continuous quantities)

  **Significance of Gradient Descent:**

  The **gradient** ∇f = (∂f/∂x, ∂f/∂y) points in the direction of steepest ascent. 
  
  Key insight: Move in the negative gradient direction to descend toward minima:
  
  ```
  x_new = x_old - α · ∂f/∂x
  y_new = y_old - α · ∂f/∂y
  ```
  
  where α is the learning rate (step size).

  **Why it helps:**
  - Uses local information (derivatives) to make informed moves
  - Much faster than random search (directed vs. random exploration)
  - Guaranteed convergence for convex functions
  - Foundation of modern machine learning (backpropagation = gradient descent)

  ---

  **Level 1: Problem Formulation and Hand Demonstration**

  **Formal Problem Definition:**

  Given:
  - Towns: {T₁, T₂, ..., Tₙ} at locations (x₁, y₁), (x₂, y₂), ..., (xₙ, yₙ)
  - Weights: w₁, w₂, ..., wₙ (population or flight frequency)

  Find: Airport location (x*, y*) that minimizes weighted sum of squared distances

  Objective function:
  ```
  f(x, y) = Σᵢ wᵢ · [(x - xᵢ)² + (y - yᵢ)²]
  ```

  **Hand Demonstration with 3 Towns:**

  ```
  Town A: location (2, 3), weight = 5
  Town B: location (8, 5), weight = 3
  Town C: location (4, 9), weight = 2
  ```

  Let's evaluate objective function at airport location (5, 6):

  ```
  Distance² from A: (5-2)² + (6-3)² = 9 + 9 = 18
  Distance² from B: (5-8)² + (6-5)² = 9 + 1 = 10
  Distance² from C: (5-4)² + (6-9)² = 1 + 9 = 10

  Weighted sum:
  f(5, 6) = 5·18 + 3·10 + 2·10
          = 90 + 30 + 20
          = 140
  ```

  Now try location (4, 5):

  ```
  Distance² from A: (4-2)² + (5-3)² = 4 + 4 = 8
  Distance² from B: (4-8)² + (5-5)² = 16 + 0 = 16
  Distance² from C: (4-4)² + (5-9)² = 0 + 16 = 16

  Weighted sum:
  f(4, 5) = 5·8 + 3·16 + 2·16
          = 40 + 48 + 32
          = 120  ← Better!
  ```

  **Random Search Algorithm Demonstration:**

  ```
  Iteration 1: Try random point (3.2, 4.7)
    → f(3.2, 4.7) = 127.38
    → Current best: (3.2, 4.7) with value 127.38

  Iteration 2: Try random point (6.1, 7.3)
    → f(6.1, 7.3) = 158.22
    → Worse, keep current best

  Iteration 3: Try random point (4.1, 5.3)
    → f(4.1, 5.3) = 118.94
    → New best! Update to (4.1, 5.3)

  ... continue for many iterations ...

  After 10,000 iterations:
    → Best found: (4.2, 5.4) with value ≈ 118.8
    → Close to optimal centroid
  ```

  ---

  **Level 2: Implementation with Gradient Descent**

  **Analytical Derivatives:**

  For f(x, y) = Σᵢ wᵢ · [(x - xᵢ)² + (y - yᵢ)²]:

  ```
  ∂f/∂x = Σᵢ wᵢ · 2(x - xᵢ) = 2 Σᵢ wᵢ(x - xᵢ)
  ∂f/∂y = Σᵢ wᵢ · 2(y - yᵢ) = 2 Σᵢ wᵢ(y - yᵢ)
  ```

  **Python Implementation:**

  ```python
  import numpy as np
  import matplotlib.pyplot as plt

  def objective(x, y, towns):
      """Compute weighted sum of squared distances."""
      total = 0
      for tx, ty, weight in towns:
          dx = x - tx
          dy = y - ty
          total += weight * (dx**2 + dy**2)
      return total

  def gradient(x, y, towns):
      """Compute analytical gradient."""
      grad_x = 0
      grad_y = 0
      for tx, ty, weight in towns:
          grad_x += 2 * weight * (x - tx)
          grad_y += 2 * weight * (y - ty)
      return grad_x, grad_y

  def gradient_descent(towns, learning_rate=0.01, iterations=1000):
      """Find optimal airport location using gradient descent."""
      # Start at random location
      x = np.random.uniform(0, 10)
      y = np.random.uniform(0, 10)
      
      history = [(x, y, objective(x, y, towns))]
      
      for i in range(iterations):
          # Compute gradient
          gx, gy = gradient(x, y, towns)
          
          # Update position (move opposite to gradient)
          x = x - learning_rate * gx
          y = y - learning_rate * gy
          
          # Track progress
          if i % 10 == 0:
              history.append((x, y, objective(x, y, towns)))
          
          # Check convergence
          if abs(gx) < 1e-6 and abs(gy) < 1e-6:
              print(f"Converged at iteration {i}")
              break
      
      return x, y, history

  def visualize_objective(towns, optimal_x, optimal_y):
      """Create heat map of objective function."""
      # Create grid
      x_range = np.linspace(0, 10, 100)
      y_range = np.linspace(0, 10, 100)
      X, Y = np.meshgrid(x_range, y_range)
      
      # Compute objective at each grid point
      Z = np.zeros_like(X)
      for i in range(X.shape[0]):
          for j in range(X.shape[1]):
              Z[i, j] = objective(X[i, j], Y[i, j], towns)
      
      # Plot heat map
      plt.figure(figsize=(10, 8))
      plt.contourf(X, Y, Z, levels=50, cmap='viridis')
      plt.colorbar(label='Objective Value')
      
      # Plot towns
      for tx, ty, weight in towns:
          plt.scatter(tx, ty, s=weight*50, c='red', 
                     marker='s', edgecolors='white', linewidths=2)
          plt.text(tx, ty, f'w={weight}', color='white', 
                  ha='center', va='center')
      
      # Plot optimal location
      plt.scatter(optimal_x, optimal_y, s=200, c='yellow', 
                 marker='*', edgecolors='black', linewidths=2)
      plt.text(optimal_x, optimal_y + 0.3, 'Airport', 
              ha='center', fontweight='bold')
      
      plt.xlabel('X coordinate')
      plt.ylabel('Y coordinate')
      plt.title('Airport Placement Optimization (Heat Map)')
      plt.grid(alpha=0.3)
      plt.show()

  # Example usage
  towns = [
      (2, 3, 5),  # (x, y, weight)
      (8, 5, 3),
      (4, 9, 2)
  ]

  optimal_x, optimal_y, history = gradient_descent(towns)
  print(f"Optimal location: ({optimal_x:.2f}, {optimal_y:.2f})")
  print(f"Objective value: {objective(optimal_x, optimal_y, towns):.2f}")

  visualize_objective(towns, optimal_x, optimal_y)
  ```

  **Output:**
  ```
  Converged at iteration 127
  Optimal location: (4.20, 5.40)
  Objective value: 118.80
  ```

  ---

  **Level 3: Proof of Weighted Centroid and Convexity Analysis**

  **Proof that optimal solution is weighted centroid:**

  To minimize f(x, y) = Σᵢ wᵢ · [(x - xᵢ)² + (y - yᵢ)²], we set gradients to zero:

  ```
  ∂f/∂x = 2 Σᵢ wᵢ(x - xᵢ) = 0
  ∂f/∂y = 2 Σᵢ wᵢ(y - yᵢ) = 0
  ```

  Solving the first equation:
  ```
  Σᵢ wᵢ(x - xᵢ) = 0
  Σᵢ wᵢx - Σᵢ wᵢxᵢ = 0
  x · Σᵢ wᵢ = Σᵢ wᵢxᵢ
  
  x* = Σᵢ wᵢxᵢ / Σᵢ wᵢ
  ```

  Similarly: y* = Σᵢ wᵢyᵢ / Σᵢ wᵢ

  This is the **weighted centroid** (center of mass).

  **Verification this is a minimum (not maximum or saddle point):**

  Compute second derivatives (Hessian matrix):
  ```
  ∂²f/∂x² = 2 Σᵢ wᵢ > 0  (sum of positive weights)
  ∂²f/∂y² = 2 Σᵢ wᵢ > 0
  ∂²f/∂x∂y = 0

  Hessian = [2Σwᵢ    0   ]
            [0    2Σwᵢ]
  ```

  Since both eigenvalues are positive (2Σwᵢ > 0), the Hessian is positive definite → local minimum.

  **Convexity Proof:**

  A function is convex if its Hessian is positive semidefinite everywhere.

  Here, Hessian = 2Σwᵢ · I (identity matrix scaled by positive constant)
  
  This is positive definite everywhere → f is strictly convex

  **Implication**: Strictly convex functions have exactly one local minimum, which is also the unique global minimum.

  ---

  **Comparison: Airport vs. 8-Queens Landscapes**

  | Property | Airport (Continuous) | 8-Queens (Discrete) |
  |----------|---------------------|---------------------|
  | **Convexity** | Strictly convex | Non-convex |
  | **Local Optima** | 1 (the global) | Many (~1000s) |
  | **Global Optima** | 1 unique | 92 solutions |
  | **Gradient** | Always points to optimum | N/A (discrete) |
  | **Search Difficulty** | Easy (follow gradient) | Hard (many traps) |
  | **Guarantees** | Convergence proven | Heuristic only |

  **Why the difference?**
  - Airport: Quadratic function (bowl-shaped surface)
  - 8-Queens: Combinatorial constraints create rugged landscape

  ---

  **Generalization: When to Use Calculus vs. Metaheuristics**

  **Use Calculus (Gradient Descent, Newton's Method) when:**

  ✓ **Convex or near-convex problems:**
  - Linear regression (least squares)
  - Logistic regression
  - Support vector machines (with convex kernel)
  - Optimal transport problems
  
  ✓ **Smooth, differentiable objectives:**
  - Neural network training (backpropagation)
  - Parameter optimization
  - Continuous control (robotics)
  
  ✓ **Advantages:**
  - Fast convergence (quadratic for Newton's method)
  - Theoretical guarantees
  - Efficient use of derivative information

  **Use Metaheuristics (SA, GA, Random Search) when:**

  ✓ **Non-convex, rugged landscapes:**
  - Combinatorial optimization (TSP, scheduling)
  - Discrete variables (binary decisions)
  - Multiple local optima
  
  ✓ **No derivatives available:**
  - Black-box functions (simulations)
  - Non-differentiable objectives
  - Noisy evaluations
  
  ✓ **Advantages:**
  - Don't get stuck in local optima
  - Work with any objective function
  - Can find diverse solutions

  **Hybrid Approaches (Best of Both):**
  - Start with metaheuristic to find good basin
  - Finish with gradient descent for precise convergence
  - Example: Genetic algorithms with local gradient refinement
  - Used in: Deep learning architecture search, hyperparameter optimization

  **Key Principle**: Match the algorithm to the problem structure. Understanding the objective function landscape is crucial for choosing effective optimization methods.
topics:
  - "Continuous Optimization"
  - "Random Search"
  - "Facility Location"
example_videos:
  - "https://www.youtube.com/watch?v=IHZwWFHWa-w"
