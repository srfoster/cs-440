id: "m2-stochastic-optimization"
type: "short-answer"
chapter: 1
question: |
  **Solve the 8-Queens problem using stochastic optimization: simulated annealing and genetic algorithms.**

  **Level 0** Discuss how randomness helps overcome the limitations of greedy hill climbing. Compare two paradigms: single-point stochastic search (simulated annealing) vs. population-based search (genetic algorithms). Why is the exploration-exploitation trade-off central to both?   Discuss the metallurgical annealing metaphor and genetic evolution metaphor for each algorithm.

  **Level 1** Using the 8-Queens formulation:
  
  **Simulated Annealing:**  Demonstrate the use of simulated annealing on a sample board. Show how the acceptance probability changes with temperature and delta. 
  
  **Genetic Algorithm:**  Demonstrate the use of a genetic algorithm on a sample population of boards. Show how selection, crossover, and mutation operate on the population. 

  **Level 2** Implement both algorithms for 8-Queens.

  **Level 3** Analyze theoretical guarantees and practical trade-offs between these algorithms.  When might a problem be better suited for one over the other?  Discuss how the objective function landscape (number of local optima, global optima) affects search difficulty and algorithm choice.
  
answer: |
  **Level 0: Randomness, Metaphors, and Exploration-Exploitation**

  **How randomness overcomes greedy hill climbing limitations:**
  - Hill climbing gets stuck in local optima (no better neighbors)
  - Randomness allows "uphill" moves to escape local peaks
  - Controlled randomness balances exploration (search new regions) vs. exploitation (refine current good solutions)

  **Two paradigms:**

  1. **Single-point stochastic search (Simulated Annealing)**
     - Maintains one current solution
     - Stochastically accepts worse moves with decreasing probability
     - Exploration → exploitation transition through temperature cooling

  2. **Population-based search (Genetic Algorithms)**
     - Maintains multiple solutions simultaneously
     - Combines features from different solutions (crossover)
     - Natural selection pressure drives toward better solutions
     - Exploration through diversity; exploitation through selection

  **Exploration-Exploitation Trade-off:**
  - **Early**: Need exploration to find promising regions (avoid premature convergence)
  - **Late**: Need exploitation to refine best solutions found
  - **SA**: Temperature controls this (high T = explore, low T = exploit)
  - **GA**: Population diversity controls this (mutation = explore, selection = exploit)

  **Metaphors:**

  *Simulated Annealing (Metallurgy):*
  - Heating metal makes atoms move freely (high energy = random exploration)
  - Slow cooling allows atoms to settle into low-energy crystal structure
  - Too fast cooling → trapped in imperfect structure (local optimum)
  - Optimal cooling schedule → perfect crystal (global optimum)

  *Genetic Algorithm (Evolution):*
  - Population of organisms with varying traits (solutions)
  - Natural selection favors fitter individuals (better objective function)
  - Sexual reproduction combines parental traits (crossover)
  - Random mutations introduce new variations (exploration)
  - Evolution toward increasingly fit populations

  ---

  **Level 1: Demonstrations**

  **Simulated Annealing on 8-Queens:**

  ```
  Initial board (5 conflicts):
  Q . . . . . . .
  . . . Q . . . .
  . . . . . . Q .
  . Q . . . . . .
  . . . . . Q . .
  . . . . . . . Q
  . . Q . . . . .
  . . . . Q . . .

  Iteration 1 (T = 100):
  - Current conflicts: 5
  - Try: Move queen in column 3 from row 1 to row 5
  - New conflicts: 7 (worse by Δ = +2)
  - Acceptance probability: exp(-2/100) = 0.98
  - Random(0,1) = 0.34 < 0.98 → ACCEPT ✓
  
  Iteration 50 (T = 50):
  - Current conflicts: 3
  - Try: Move queen in column 6 from row 2 to row 4
  - New conflicts: 4 (worse by Δ = +1)
  - Acceptance probability: exp(-1/50) = 0.98
  - Random(0,1) = 0.85 < 0.98 → ACCEPT ✓
  
  Iteration 200 (T = 5):
  - Current conflicts: 1
  - Try: Move queen in column 0 from row 0 to row 7
  - New conflicts: 3 (worse by Δ = +2)
  - Acceptance probability: exp(-2/5) = 0.67
  - Random(0,1) = 0.92 > 0.67 → REJECT ✗
  
  Iteration 500 (T = 0.1):
  - Current conflicts: 0 → SOLUTION FOUND! ✓
  ```

  Note: As T decreases, worse moves become less likely (more greedy behavior)

  ---

  **Genetic Algorithm on 8-Queens:**

  ```
  Initial Population (4 individuals):
  Board A: [0,1,2,3,4,5,6,7] conflicts=28 fitness=0.034
  Board B: [0,4,7,5,2,6,1,3] conflicts=3  fitness=0.250
  Board C: [1,3,5,7,2,0,6,4] conflicts=2  fitness=0.333
  Board D: [2,5,1,4,7,0,3,6] conflicts=4  fitness=0.200

  Generation 1:

  Step 1 - Selection (Tournament, k=2):
  - Parent 1: Compare B vs D → Select B (better fitness)
  - Parent 2: Compare C vs A → Select C (better fitness)

  Step 2 - Crossover (One-point at position 4):
  - Parent 1: [0,4,7,5 | 2,6,1,3]
  - Parent 2: [1,3,5,7 | 2,0,6,4]
  - Child 1:  [0,4,7,5 | 2,0,6,4] conflicts=1
  - Child 2:  [1,3,5,7 | 2,6,1,3] conflicts=3

  Step 3 - Mutation (5% probability per gene):
  - Child 1: Mutate position 2: 7→6
  - Result:  [0,4,6,5,2,0,6,4] conflicts=2

  New Population:
  - Keep best 2 from old: C, B
  - Add best 2 children: [0,4,7,5,2,0,6,4], [1,3,5,7,2,6,1,3]

  After 50 generations: Solution found with 0 conflicts
  ```

  ---

  **Level 2: Implementations**

  **Simulated Annealing:**

  ```python
  import random
  import math

  def simulated_annealing_8queens(max_iter=10000):
      # Start with random board
      board = [random.randint(0, 7) for _ in range(8)]
      current_conflicts = conflicts(board)
      
      # Temperature parameters
      T = 100.0
      alpha = 0.99  # Cooling rate
      T_min = 0.01
      
      for iteration in range(max_iter):
          if current_conflicts == 0:
              return board, iteration
          
          if T < T_min:
              break
          
          # Generate neighbor (move one queen)
          neighbor = board[:]
          col = random.randint(0, 7)
          neighbor[col] = random.randint(0, 7)
          
          neighbor_conflicts = conflicts(neighbor)
          delta = neighbor_conflicts - current_conflicts
          
          # Accept if better, or probabilistically if worse
          if delta < 0:
              board = neighbor
              current_conflicts = neighbor_conflicts
          else:
              acceptance_prob = math.exp(-delta / T)
              if random.random() < acceptance_prob:
                  board = neighbor
                  current_conflicts = neighbor_conflicts
          
          # Cool down
          T *= alpha
      
      return board, max_iter

  # Helper function from previous answer
  def conflicts(board):
      count = 0
      for i in range(len(board)):
          for j in range(i+1, len(board)):
              if board[i] == board[j] or \
                 abs(board[i] - board[j]) == abs(i - j):
                  count += 1
      return count
  ```

  **Genetic Algorithm:**

  ```python
  import random

  def genetic_algorithm_8queens(pop_size=100, generations=1000):
      # Initialize population
      population = [[random.randint(0, 7) for _ in range(8)] 
                    for _ in range(pop_size)]
      
      for gen in range(generations):
          # Evaluate fitness
          fitness_scores = []
          for board in population:
              c = conflicts(board)
              fitness_scores.append(1.0 / (1.0 + c))
          
          # Check for solution
          if max(fitness_scores) == 1.0:
              idx = fitness_scores.index(1.0)
              return population[idx], gen
          
          # Create new population
          new_population = []
          
          # Elitism: keep best 10%
          elite_count = pop_size // 10
          sorted_pop = sorted(zip(fitness_scores, population), 
                            reverse=True)
          new_population.extend([ind for _, ind in sorted_pop[:elite_count]])
          
          # Generate offspring
          while len(new_population) < pop_size:
              # Tournament selection
              parent1 = tournament_select(population, fitness_scores, k=3)
              parent2 = tournament_select(population, fitness_scores, k=3)
              
              # Crossover
              child1, child2 = crossover(parent1, parent2)
              
              # Mutation
              child1 = mutate(child1, mutation_rate=0.1)
              child2 = mutate(child2, mutation_rate=0.1)
              
              new_population.extend([child1, child2])
          
          population = new_population[:pop_size]
      
      return None, generations

  def tournament_select(population, fitness_scores, k=3):
      """Select best from k random individuals."""
      indices = random.sample(range(len(population)), k)
      best_idx = max(indices, key=lambda i: fitness_scores[i])
      return population[best_idx][:]

  def crossover(parent1, parent2):
      """One-point crossover."""
      point = random.randint(1, 7)
      child1 = parent1[:point] + parent2[point:]
      child2 = parent2[:point] + parent1[point:]
      return child1, child2

  def mutate(board, mutation_rate=0.1):
      """Randomly change genes with given probability."""
      mutated = board[:]
      for i in range(len(mutated)):
          if random.random() < mutation_rate:
              mutated[i] = random.randint(0, 7)
      return mutated
  ```

  ---

  **Level 3: Theoretical Analysis and Trade-offs**

  **Theoretical Guarantees:**

  *Simulated Annealing:*
  - **Theorem**: With logarithmic cooling schedule T(t) = c/log(t), SA converges to global optimum with probability 1
  - **In practice**: Too slow; use geometric cooling (T = αT) for 99.5-99.99% success
  - **No population needed**: Memory efficient O(n) for state size n

  *Genetic Algorithms:*
  - **Schema Theorem**: Good building blocks (schemata) propagate exponentially
  - **No convergence guarantee**: Can get stuck if diversity lost
  - **Population required**: Memory intensive O(p×n) for population size p

  **Practical Performance on 8-Queens:**

  | Algorithm | Success Rate | Avg Iterations | Memory | Best For |
  |-----------|--------------|----------------|--------|----------|
  | Hill Climbing | 14% | 4 | O(n) | Quick attempts |
  | Random Restart | 100% | 6 restarts | O(n) | Simple problems |
  | Simulated Annealing | 95-99% | 5000 | O(n) | Complex landscapes |
  | Genetic Algorithm | 98% | 100 gens | O(p×n) | Crossover benefits |

  **When to use which algorithm:**

  **Simulated Annealing better when:**
  - Limited memory (single solution)
  - Objective function landscape has deep local optima
  - Solutions don't have meaningful "building blocks" to combine
  - Need theoretical convergence guarantees
  - Examples: TSP, circuit layout, scheduling

  **Genetic Algorithms better when:**
  - Solutions have meaningful substructures that combine well
  - Multiple diverse solutions are valuable (not just one best)
  - Parallel evaluation possible (fitness of population)
  - Problem naturally encoded as strings/sequences
  - Examples: Neural network architecture search, feature selection, game strategies

  **Impact of Objective Function Landscape:**

  1. **Many local optima, few global optima** (e.g., TSP):
     - SA needs slow cooling to thoroughly explore
     - GA needs high diversity (high mutation rate)
     - Both struggle but outperform pure hill climbing

  2. **Smooth landscape, multiple global optima** (e.g., 8-Queens):
     - SA converges quickly with aggressive cooling
     - GA may find multiple optimal solutions
     - Even random restart works well

  3. **Deceptive landscapes** (fitness increases toward local optima):
     - SA can escape via temperature
     - GA vulnerable to premature convergence (selection pressure pushes toward deceptive peaks)
     - May need diversity preservation mechanisms

  4. **Plateaus** (large regions of equal fitness):
     - SA random walk on plateaus (slow)
     - GA maintains diversity better (population spreads across plateau)
     - Hybrid approaches often best

  The key insight: **No Free Lunch Theorem** states no algorithm is universally best. Algorithm choice depends on problem structure, and understanding the objective function landscape is critical for effective optimization.
topics:
  - "Simulated Annealing"
  - "Genetic Algorithms"
  - "Stochastic Search"
  - "Evolutionary Computation"
  - "Population-based Search"
vocab_answer:
  - word: "temperature"
    definition: "A parameter controlling randomness in simulated annealing"
  - word: "cooling schedule"
    definition: "The rate at which temperature decreases over time"
  - word: "crossover"
    definition: "Combining genetic material from two parents to create offspring"
  - word: "mutation"
    definition: "Random changes to maintain diversity in the population"
example_videos:
  - "https://www.youtube.com/watch?v=eBmU1ONJ-os"
