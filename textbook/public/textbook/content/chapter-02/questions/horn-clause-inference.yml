id: "m5-horn-clause-inference"
type: "short-answer"
chapter: 2
question: |
  **Reason about a melodramatic love triangle using forward chaining, backward chaining, and search-based inference on Horn clauses.**

  Your soap opera knowledge base has rules: Loves(X, Y) ∧ Dated(Y, Z) ∧ Friend(X, Z) → Heartbroken(X). Heartbroken(X) ∧ Drunk(X) → Confesses(X, secret_of(X)). Confesses(X, secret_of(Y)) → Betrayed(Y). Facts: Loves(Elena, Stefan), Dated(Stefan, Caroline), Friend(Elena, Caroline), Drunk(Elena), secret_of(Elena) = "Stefan's secret." Query: Betrayed(Stefan)? Three approaches: (1) Forward chaining: derive all consequences from facts, (2) Backward chaining: work from query back to facts, (3) Search: treat inference as state-space exploration. This matters because Horn clauses (rules with one conclusion) are computationally tractable—linear-time inference—unlike general logic (exponential). Most real-world reasoning (expert systems, Prolog, rule-based AI) uses Horn clauses for this reason.

  **Level 0** Discuss why Horn clauses restrict expressiveness for tractability. General logic allows disjunctions in conclusions ("Loves(X, Y) ∨ Hates(X, Y)"), requiring exponential case splits. Horn clauses: exactly one positive literal ("Loves(X, Y)"), enabling deterministic inference. Compare three perspectives: Forward (data-driven, good for "tell me everything"), Backward (goal-driven, good for "does this hold?"), Search (unifying view). Connect to Prolog: backward chaining with depth-first search.

  **Level 1** Define Horn clauses: B₁ ∧ B₂ ∧ ... ∧ Bₙ → H (premises → head).
  
  **Forward Chaining on Love Triangle:** Start with facts: {Loves(Elena, Stefan), Dated(Stefan, Caroline), Friend(Elena, Caroline), Drunk(Elena), secret_of(Elena)="Stefan's secret"}. Iteration 1: Rule "Loves ∧ Dated ∧ Friend → Heartbroken" fires. All premises satisfied. Add Heartbroken(Elena). Iteration 2: Rule "Heartbroken ∧ Drunk → Confesses" fires. Add Confesses(Elena, "Stefan's secret"). Iteration 3: Rule "Confesses(X, secret_of(Y)) → Betrayed(Y)" fires. Add Betrayed(Stefan). Done. Query Betrayed(Stefan)? Yes. Pseudocode: FORWARD_CHAIN(rules, facts, query): repeat until no new facts: for each rule, if all premises in facts, add head. Check if query in facts.
  
  **Backward Chaining on Love Triangle:** Query Betrayed(Stefan). Find rule concluding Betrayed: "Confesses(X, secret_of(Stefan)) → Betrayed(Stefan)." Subgoal: Confesses(Elena, "Stefan's secret") (after unification). Find rule: "Heartbroken(Elena) ∧ Drunk(Elena) → Confesses(Elena, secret_of(Elena))." Subgoals: Heartbroken(Elena), Drunk(Elena). Drunk(Elena) is fact ✓. Heartbroken(Elena): find rule "Loves(Elena, Stefan) ∧ Dated(Stefan, Caroline) ∧ Friend(Elena, Caroline) → Heartbroken(Elena)." All premises are facts ✓. Backtrack: all subgoals satisfied. Query true. Pseudocode: BACKWARD_CHAIN(rules, facts, goal, visited): if goal in facts, true; else find rule concluding goal, recursively prove premises.
  
  **Inference as BFS Search:** State = set of derived facts. Start = initial facts. Actions = rule applications. Goal = state containing query. BFS explores: {initial facts} → {initial + Heartbroken(Elena)} → {initial + Heartbroken + Confesses(Elena, ...)} → {initial + ... + Betrayed(Stefan)} ✓. Pseudocode: PROOF_BFS(rules, facts, query): queue=[facts], while queue: state=dequeue, if query in state return true, for each rule: if premises in state, enqueue state + {head}.

  **Level 2** Implement all three for soap opera KB: rules about Heartbroken, Jealous, Schemes, Betrayed, Revenge. Facts: 10 characters, 20 relationships. Query: Revenge(Villain, Hero). Compare: Forward derives ~50 facts. Backward explores ~15 nodes. BFS similar to backward. Test: Which is faster for single queries? (Backward.) Which for "derive everything"? (Forward.) Implement cycle detection in backward chaining (track visited goals to avoid infinite loops like X → Y, Y → X).

  **Level 3** Prove soundness (all three only derive valid conclusions) and completeness (all three find proofs if they exist) for Horn clauses. Analyze complexity: Forward O(pn) where p = max premises, n = facts/rules (worst case: all rules fire every iteration until fixed point). Backward O(branching^depth): depends on rule structure. BFS O(branching^depth). Discuss: Forward in RETE algorithm (expert systems, production rules): compile rules into network for incremental updates. Backward in Prolog: depth-first variant with backtracking for multiple solutions. Why forward slow for specific queries: derives many irrelevant facts. Why backward loops without visited tracking: circular rules.
answer: "Forward chaining (data-driven): maintain fact base, repeatedly find rules with all premises satisfied, add conclusions. Backward chaining (goal-driven): start with query, recursively prove premises of rules that conclude it, track visited to avoid cycles. Search view: states = fact sets, actions = rule applications, BFS to goal. All three are sound and complete for Horn clauses. Forward best for deriving all consequences, backward efficient for single queries, search view unifies both perspectives."
topics:
  - "Forward Chaining"
  - "Backward Chaining"
  - "Horn Clauses"
  - "Inference as Search"
vocab_answer:
  - word: "Horn clause"
    definition: "A logical clause with at most one positive literal"
  - word: "data-driven"
    definition: "Reasoning that starts from known facts and derives conclusions"
  - word: "goal-driven"
    definition: "Reasoning that starts from a query and works backward"
example_videos:
  - "https://www.youtube.com/watch?v=vPRDN1Y8kHg"
